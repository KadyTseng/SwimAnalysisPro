# SwimAnalysisPro/BD/stroke_analysis/backstroke_butterfly_freestyle_stroke_stage.py
import cv2
import pandas as pd
import numpy as np
from scipy.ndimage import uniform_filter1d


def read_txt(path):
    data = []
    with open(path, "r") as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) > 20:
                try:
                    frame_id = int(parts[0])
                    x_center = float(parts[2])
                    width = float(parts[4])
                    head_y = float(parts[8])
                    data.append((frame_id, x_center, width, head_y))
                except:
                    continue
    return pd.DataFrame(data, columns=["frame_id", "x_center", "width", "head_y"])


def detect_waterline_y(video_path, lower_blue=(80, 50, 50), upper_blue=(140, 255, 255)):
    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    cap.release()
    if not ret:
        raise RuntimeError("ç„¡æ³•è®€å–å½±ç‰‡")

    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, np.array(lower_blue), np.array(upper_blue))
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        waterline_y = np.min(max(contours, key=cv2.contourArea)[:, :, 1])
    else:
        raise RuntimeError("ç„¡æ³•åµæ¸¬æ°´é¢ç·š")
    return waterline_y


def find_submerged_segments(df, waterline_y, top_n=2):
    segments = []
    current = []
    for _, row in df.iterrows():
        if row["head_y"] >= waterline_y:
            current.append(row["frame_id"])
        else:
            if current:
                segments.append(current)
                current = []
    if current:
        segments.append(current)

    segments.sort(key=len, reverse=True)
    top_segments = segments[:top_n]
    top_segments.sort(key=lambda seg: seg[0])
    return [(seg[0], seg[-1]) for seg in top_segments]


# def find_touch_frame(df, threshold=3800):
#     max_frame = df['frame_id'].max()
#     half_frame = max_frame // 2
#     for _, row in df.iterrows():
#         if row['frame_id'] >= half_frame:
#             if row['x_center'] + row['width'] / 2 > threshold:
#                 return int(row['frame_id'])
#     return None
def find_touch_frame(df, video_width):
    """
    æ‰¾è§¸ç‰†å¹€ï¼šç•¶ x_center + width/2 > video_width - 40
    """
    threshold = video_width - 40
    max_frame = df["frame_id"].max()
    half_frame = max_frame // 2
    for _, row in df.iterrows():
        if row["frame_id"] >= half_frame:
            if row["x_center"] + row["width"] / 2 > threshold:
                return int(row["frame_id"])
    return None


def extract_stroke_segments(txt_path, video_path, waterline_y):
    df = read_txt(txt_path)

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"ç„¡æ³•é–‹å•Ÿå½±ç‰‡: {video_path}")

    v_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    cap.release()

    (s1, e1), (s2, e2) = find_submerged_segments(df, waterline_y)
    touch_frame = find_touch_frame(df, v_width)

    return e1, s2, e2, touch_frame, waterline_y


def extract_columns_in_range(txt_path, range1, range2):
    def parse_line(line):
        parts = line.strip().split()
        if len(parts) > 17:
            frame_id = int(parts[0])
            col10 = float(parts[10])
            col11 = float(parts[11])
            col16 = float(parts[16])
            col17 = float(parts[17])
            col19 = float(parts[19])
            return frame_id, col10, col11, col16, col17, col19
        return None

    range1_data = []
    range2_data = []
    with open(txt_path, "r") as f:
        for line in f:
            parsed = parse_line(line)
            if parsed:
                frame_id, col10, col11, col16, col17, col19 = parsed
                if range1[0] <= frame_id <= range1[1]:
                    range1_data.append((frame_id, col10, col11, col16, col17, col19))
                elif range2[0] <= frame_id <= range2[1]:
                    range2_data.append((frame_id, col10, col11, col16, col17, col19))
    return {"range1": range1_data, "range2": range2_data}


def plot_intersection_from_smoothed(data_dict, smooth_size=10):
    intersection_result = {}
    for key, values in data_dict.items():
        frames = np.array([v[0] for v in values])
        col10s = np.array([v[1] for v in values])
        col16s = np.array([v[3] for v in values])
        col10s_smooth = uniform_filter1d(col10s, size=smooth_size)
        col16s_smooth = uniform_filter1d(col16s, size=smooth_size)
        diff = col10s_smooth - col16s_smooth
        sign_change = np.where(np.diff(np.sign(diff)) != 0)[0]
        intersection_frames = frames[sign_change]
        intersection_result[key] = intersection_frames.tolist()
    return intersection_result


# BD/stroke_analysis/backstroke_butterfly_freestyle_stroke_stage.py


def count_strokes_from_phases(phase_results):
    """
    è¨ˆç®—åˆ’æ‰‹æ¬¡æ•¸ï¼šçµ±è¨ˆ range1 å’Œ range2 ä¸­åŒ…å«çš„å¹€æ•¸åˆ—è¡¨é•·åº¦ã€‚
    (æ³¨æ„ï¼šæ­¤å‡½æ•¸å‡è¨­ phase_results['rangeX'] çš„å€¼æœ¬èº«å°±æ˜¯ä¸€å€‹å¹€æ•¸åˆ—è¡¨ã€‚)
    """
    # print("--- DEBUG: Phase Results Type Check ---")
    # print(f"Type of phase_results: {type(phase_results)}")
    # print(f"Content (First 500 chars): {str(phase_results)[:500]}")
    # print("--------------------------------------")
    # *** ä¿®æ­£é» 1: ç¢ºä¿è¼¸å…¥æ˜¯å­—å…¸ ***
    if not isinstance(phase_results, dict):
        # é€™è£¡æ‡‰è©²æ‹‹å‡ºéŒ¯èª¤æˆ–è¿”å› 0ï¼Œä»¥é˜²è¼¸å…¥é¡å‹éŒ¯èª¤
        return {"total_count": 0, "stroke_frames": []}

    # *** ä¿®æ­£é» 2: ç›´æ¥ç²å– range1, range2 çš„åˆ—è¡¨é•·åº¦ ***
    # é€™è£¡å‡è¨­ phase_results['range1'] çš„å€¼å°±æ˜¯æˆ‘å€‘æƒ³è¦è¨ˆç®—é•·åº¦çš„åˆ—è¡¨ã€‚

    # ç¢ºä¿ range1/range2 çš„å€¼æ˜¯åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡è¿”å›ç©ºåˆ—è¡¨ []
    recovery_list_r1 = phase_results.get("range1", [])
    recovery_list_r2 = phase_results.get("range2", [])

    # ç”±æ–¼æˆ‘å€‘æ²’æœ‰å­éµï¼Œç›´æ¥è¨ˆç®—åˆ—è¡¨é•·åº¦
    strokes_range1 = len(recovery_list_r1)
    strokes_range2 = len(recovery_list_r2)
    total_strokes = strokes_range1 + strokes_range2

    # åˆä½µæ‰€æœ‰å¹€æ•¸ (å‡è¨­é€™æ˜¯åˆ’æ°´é»)
    all_stroke_frames = recovery_list_r1 + recovery_list_r2

    return {
        "total_count": total_strokes,
        "range1_recovery_count": strokes_range1,
        "range2_recovery_count": strokes_range2,
        "stroke_frames": all_stroke_frames,
        "phase_regions_detail": phase_results,
    }


import os
from .backstroke_butterfly_freestyle_stroke_phase_plot import (
    plot_phase_on_col11_col17,
)  # åˆ†é–‹ç®¡ç† plot å¯¦ä½œ


def run_backstroke_butterfly_analysis(
    txt_path: str, video_path: str, waterline_y: float
):
    """
    åŸ·è¡Œä»°å¼/è¶å¼çš„åˆ†ææµç¨‹ï¼š
    1. æ‰¾å‡ºæœ‰æ•ˆåˆ†æå€é–“ (e1, s2, e2, touch_frame)ã€‚
    2. è¨ˆç®—è‚©é—œç¯€èˆ‡æ‰‹è…•çš„äº¤æœƒé» (ä½œç‚ºåŠƒåˆ†éšæ®µçš„ä¾æ“š)ã€‚
    3. å‘¼å«ç¹ªåœ–å‡½æ•¸è¼¸å‡ºæ³¢å½¢åœ–å’Œçµæœ TXTã€‚
    """
    # ç¢ºä¿ extract_stroke_segments å·²ç¶“è¢«å®šç¾©åœ¨ä¸Šé¢æˆ–å°å…¥
    # å‡è¨­ extract_stroke_segments è¿”å› 5 å€‹å€¼
    e1, s2, e2, touch_frame, waterline_y = extract_stroke_segments(
        txt_path, video_path, waterline_y
    )

    if None in (e1, s2, e2):  # é€™è£¡æˆ‘å€‘åªéœ€è¦æª¢æŸ¥ e1, s2, e2 æ˜¯å¦æœ‰æ•ˆ
        print(f"âš ï¸ å€é–“è³‡è¨Šç¼ºå¤±ï¼Œè·³éå½±ç‰‡: {video_path} (æ ¸å¿ƒåˆ†æ®µä¸è¶³)")
        return {"status": "skipped", "reason": "core segments missing"}

        # --- ä¿®æ­£é»ï¼šå®šç¾©åˆ†æçµ‚é» ---
    if touch_frame is None:
        # å¦‚æœæ²’æœ‰åµæ¸¬åˆ°è§¸ç‰†ï¼Œç²å–å½±ç‰‡çš„ç¸½å¹€æ•¸ä½œç‚ºåˆ†æçµ‚é»
        cap = cv2.VideoCapture(video_path)
        last_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()
        analysis_end_frame = last_frame - 5  # ä½¿ç”¨å½±ç‰‡æœ€å¾Œ5å¹€
        print("åµæ¸¬ä¸åˆ°è§¸ç‰†å¹€ï¼Œä½¿ç”¨å½±ç‰‡æœ€å¾Œä¸€å¹€ä½œç‚ºåˆ†æçµ‚é»ã€‚")
    else:
        analysis_end_frame = touch_frame

    range1 = (e1, s2)
    range2 = (e2, analysis_end_frame)

    # æ“·å–æ‰€éœ€æ¬„ä½æ•¸æ“š
    data = extract_columns_in_range(txt_path, range1, range2)

    # æ‰¾å‡ºåˆ’æ‰‹éšæ®µäº¤æœƒé»
    intersection_dict = plot_intersection_from_smoothed(data)

    base, _ = os.path.splitext(video_path)
    output_txt = base + ".a.txt"

    # åŸ·è¡Œç¹ªåœ–å’Œçµæœè¼¸å‡º
    full_phase_regions = plot_phase_on_col11_col17(
        data,
        intersection_dict,
        waterline_y,
        output_txt=output_txt,
    )

    # è¿”å›åŠƒåˆ†çµæœï¼Œä¾› orchestrator é€²è¡Œè¨ˆæ•¸ (Step 7)
    return {
        "status": "success",
        "phase_data": intersection_dict,
        "full_phase_regions": full_phase_regions,  # ğŸ¯ ä¿®æ­£é» B: æ–°å¢é€™å€‹éµï¼Œå›å‚³å®Œæ•´çš„éšæ®µå€åŸŸ
        "output_txt": output_txt,
        "analysis_end_frame": analysis_end_frame,
    }


# ====demo ====


# def main():

#     txt_path = r"D:\Kady\swimmer coco\anvanced stroke analysis\stroke_stage\butterfly\Excellent_20230414_butterfly_M_3 (1)_1.txt"
#     video_path = r"D:\Kady\swimmer coco\anvanced stroke analysis\stroke_stage\butterfly\Excellent_20230414_butterfly_M_3 (1).mp4"

#     # 1. è‡ªå‹•åµæ¸¬æ°´é¢ç·š
#     waterline_y = detect_waterline_y(video_path)

#     # 2. è®€å–è³‡æ–™ + æ‰¾å‡ºæ½›æ³³å€é–“ + è§¸ç‰†æ™‚é–“é»
#     df = read_txt(txt_path)
#     (s1, e1), (s2, e2) = find_submerged_segments(df, waterline_y)
#     touch_frame = find_touch_frame(df)

#     # 3. æ“·å–æœ‰æ•ˆåˆ†ææ®µè½
#     range1 = (e1, s2)
#     range2 = (e2, touch_frame)
#     data = extract_columns_in_range(txt_path, range1, range2)

#     # 4. æ‰¾äº¤æœƒé»
#     intersection_dict = plot_intersection_from_smoothed(data)

#     # 5. ç•«åœ–ä¸¦æ¨™è¨˜æ¨é€²/æ‹‰æ°´/å¾©åŸå€æ®µ
#     plot_phase_on_col11_col17(data, intersection_dict, waterline_y)


# if __name__ == "__main__":
#     main()

# ==== demo ====

# def main():
#     folder = r"D:\Kady\swimmer coco\anvanced stroke analysis\stroke_stage\backstroke"

#     for fname in os.listdir(folder):
#         if fname.endswith(".mp4") and not fname.endswith("_1.mp4"):
#             video_path = os.path.join(folder, fname)
#             txt_name = os.path.splitext(fname)[0] + "_1.txt"
#             txt_path = os.path.join(folder, txt_name)

#             if not os.path.exists(txt_path):
#                 print(f"âš ï¸ æ‰¾ä¸åˆ°å°æ‡‰çš„ txtï¼š{txt_path}")
#                 continue

#             print(f"\nğŸš€ è™•ç†å½±ç‰‡ï¼š{video_path}")
#             run_backstroke_butterfly_analysis(txt_path, video_path)


# if __name__ == "__main__":
#     main()
